{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nClassify a tweet as being one of the following categories:\\n601:\\n602:\\n603:\\n604:\\n605:\\n606:\\n607:\\n\\nCurrently only supports english tweets.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Classify a tweet as being one of the following categories:\n",
    "601:\n",
    "602:\n",
    "603:\n",
    "604:\n",
    "605:\n",
    "606:\n",
    "607:\n",
    "\n",
    "Currently only supports english tweets.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(\"..\", \"..\", \"..\", \"src\")))\n",
    "\n",
    "from time import perf_counter\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "#from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize.casual import TweetTokenizer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertForSequenceClassification\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "from common.app import App\n",
    "from common.helpers import Helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 238523 entries, 0 to 238522\n",
      "Data columns (total 17 columns):\n",
      " #   Column           Non-Null Count   Dtype  \n",
      "---  ------           --------------   -----  \n",
      " 0   tweet_id         238523 non-null  object \n",
      " 1   covid_theme      238523 non-null  int64  \n",
      " 2   created_at       238523 non-null  object \n",
      " 3   handle           238523 non-null  object \n",
      " 4   name             238523 non-null  object \n",
      " 5   old_text         152734 non-null  object \n",
      " 6   text             237543 non-null  object \n",
      " 7   url              238256 non-null  object \n",
      " 8   type             238523 non-null  object \n",
      " 9   retweets         233824 non-null  float64\n",
      " 10  favorites        233824 non-null  float64\n",
      " 11  topic            85303 non-null   float64\n",
      " 12  subcat           15813 non-null   float64\n",
      " 13  position         15813 non-null   float64\n",
      " 14  frame            15813 non-null   float64\n",
      " 15  theme_hardcoded  32524 non-null   object \n",
      " 16  en_detect        238523 non-null  bool   \n",
      "dtypes: bool(1), float64(6), int64(1), object(9)\n",
      "memory usage: 29.3+ MB\n"
     ]
    }
   ],
   "source": [
    "app_run = App(debug=False)\n",
    "DATA_PATH = os.path.join(app_run.root_dir, \"interactive\", \"data\")\n",
    "PKL_PATH = os.path.join(DATA_PATH, \"pkl\")\n",
    "MODELS_PATH = os.path.join(app_run.root_dir, \"interactive\", \"data\", \"models\")\n",
    "df = pd.read_pickle(os.path.join(data_path, \"db_en_detect.pkl\"))\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 59242 entries, 1225 to 234043\n",
      "Data columns (total 17 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   tweet_id         59242 non-null  object \n",
      " 1   covid_theme      59242 non-null  int64  \n",
      " 2   created_at       59242 non-null  object \n",
      " 3   handle           59242 non-null  object \n",
      " 4   name             59242 non-null  object \n",
      " 5   old_text         32926 non-null  object \n",
      " 6   text             59242 non-null  object \n",
      " 7   url              59242 non-null  object \n",
      " 8   type             59242 non-null  object \n",
      " 9   retweets         55742 non-null  float64\n",
      " 10  favorites        55742 non-null  float64\n",
      " 11  topic            59242 non-null  float64\n",
      " 12  subcat           9745 non-null   float64\n",
      " 13  position         9745 non-null   float64\n",
      " 14  frame            9745 non-null   float64\n",
      " 15  theme_hardcoded  1849 non-null   object \n",
      " 16  en_detect        59242 non-null  bool   \n",
      "dtypes: bool(1), float64(6), int64(1), object(9)\n",
      "memory usage: 7.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# Keep english tweets that are coded and not 608\n",
    "df = df[(df[\"en_detect\"] == True) & (~df[\"topic\"].isnull()) & (~df[\"topic\"].isin([608, 608.0]))]\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 59242 entries, 1225 to 234043\n",
      "Data columns (total 17 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   tweet_id         59242 non-null  object \n",
      " 1   covid_theme      59242 non-null  int64  \n",
      " 2   created_at       59242 non-null  object \n",
      " 3   handle           59242 non-null  object \n",
      " 4   name             59242 non-null  object \n",
      " 5   old_text         32926 non-null  object \n",
      " 6   text             59242 non-null  object \n",
      " 7   url              59242 non-null  object \n",
      " 8   type             59242 non-null  object \n",
      " 9   retweets         55742 non-null  float64\n",
      " 10  favorites        55742 non-null  float64\n",
      " 11  topic            59242 non-null  int64  \n",
      " 12  subcat           9745 non-null   float64\n",
      " 13  position         9745 non-null   float64\n",
      " 14  frame            9745 non-null   float64\n",
      " 15  theme_hardcoded  1849 non-null   object \n",
      " 16  en_detect        59242 non-null  bool   \n",
      "dtypes: bool(1), float64(5), int64(2), object(9)\n",
      "memory usage: 7.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# topic, subcat, position and frame to int\n",
    "df[\"topic\"] = df[\"topic\"].astype(int)\n",
    "# df[\"subcat\"] = df[\"subcat\"].astype(int)\n",
    "# df[\"position\"] = df[\"position\"].astype(int)\n",
    "# df[\"frame\"] = df[\"frame\"].astype(int)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train.shape=(42653, 17) df_valid.shape=(10664, 17) df_test.shape=(5925, 17)\n"
     ]
    }
   ],
   "source": [
    "# Set seed\n",
    "SEED = 31415\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# Device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = \"cpu\"\n",
    "\n",
    "# Train test split\n",
    "df_train, df_test = train_test_split(df, test_size=0.1, random_state=SEED)\n",
    "df_train, df_valid = train_test_split(df_train, test_size=0.2, random_state=SEED)\n",
    "\n",
    "print(f\"{df_train.shape=} {df_valid.shape=} {df_test.shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>topic</th>\n",
       "      <th>prop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>602</td>\n",
       "      <td>27315</td>\n",
       "      <td>0.461075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>601</td>\n",
       "      <td>9737</td>\n",
       "      <td>0.164360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>605</td>\n",
       "      <td>8970</td>\n",
       "      <td>0.151413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>604</td>\n",
       "      <td>7708</td>\n",
       "      <td>0.130110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>603</td>\n",
       "      <td>4663</td>\n",
       "      <td>0.078711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>606</td>\n",
       "      <td>508</td>\n",
       "      <td>0.008575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>607</td>\n",
       "      <td>341</td>\n",
       "      <td>0.005756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  topic      prop\n",
       "0    602  27315  0.461075\n",
       "1    601   9737  0.164360\n",
       "2    605   8970  0.151413\n",
       "3    604   7708  0.130110\n",
       "4    603   4663  0.078711\n",
       "5    606    508  0.008575\n",
       "6    607    341  0.005756"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>topic</th>\n",
       "      <th>prop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>602</td>\n",
       "      <td>19642</td>\n",
       "      <td>0.460507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>601</td>\n",
       "      <td>7035</td>\n",
       "      <td>0.164936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>605</td>\n",
       "      <td>6433</td>\n",
       "      <td>0.150822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>604</td>\n",
       "      <td>5542</td>\n",
       "      <td>0.129932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>603</td>\n",
       "      <td>3381</td>\n",
       "      <td>0.079268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>606</td>\n",
       "      <td>363</td>\n",
       "      <td>0.008511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>607</td>\n",
       "      <td>257</td>\n",
       "      <td>0.006025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  topic      prop\n",
       "0    602  19642  0.460507\n",
       "1    601   7035  0.164936\n",
       "2    605   6433  0.150822\n",
       "3    604   5542  0.129932\n",
       "4    603   3381  0.079268\n",
       "5    606    363  0.008511\n",
       "6    607    257  0.006025"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>topic</th>\n",
       "      <th>prop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>602</td>\n",
       "      <td>4975</td>\n",
       "      <td>0.466523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>601</td>\n",
       "      <td>1750</td>\n",
       "      <td>0.164104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>605</td>\n",
       "      <td>1579</td>\n",
       "      <td>0.148068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>604</td>\n",
       "      <td>1417</td>\n",
       "      <td>0.132877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>603</td>\n",
       "      <td>797</td>\n",
       "      <td>0.074737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>606</td>\n",
       "      <td>98</td>\n",
       "      <td>0.009190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>607</td>\n",
       "      <td>48</td>\n",
       "      <td>0.004501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  topic      prop\n",
       "0    602   4975  0.466523\n",
       "1    601   1750  0.164104\n",
       "2    605   1579  0.148068\n",
       "3    604   1417  0.132877\n",
       "4    603    797  0.074737\n",
       "5    606     98  0.009190\n",
       "6    607     48  0.004501"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>topic</th>\n",
       "      <th>prop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>602</td>\n",
       "      <td>2698</td>\n",
       "      <td>0.455359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>605</td>\n",
       "      <td>958</td>\n",
       "      <td>0.161688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>601</td>\n",
       "      <td>952</td>\n",
       "      <td>0.160675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>604</td>\n",
       "      <td>749</td>\n",
       "      <td>0.126414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>603</td>\n",
       "      <td>485</td>\n",
       "      <td>0.081857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>606</td>\n",
       "      <td>47</td>\n",
       "      <td>0.007932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>607</td>\n",
       "      <td>36</td>\n",
       "      <td>0.006076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  topic      prop\n",
       "0    602   2698  0.455359\n",
       "1    605    958  0.161688\n",
       "2    601    952  0.160675\n",
       "3    604    749  0.126414\n",
       "4    603    485  0.081857\n",
       "5    606     47  0.007932\n",
       "6    607     36  0.006076"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEfCAYAAACjwKoqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAWTUlEQVR4nO3dfZRU9X3H8fdkxWAiysOaDWGNi0rsUVQwgjQooGmVhzRoolaaKCUoyVHSPNKsMa05keQQ08RIo6QmUqARAxFbqWCIjSISo4CKCgQLApYlyKOoCaIg0z9+v5HruAuzu7NzZ9j365x75s537r37XXTnc+/v3rmTyWazSJLat/ek3YAkKX2GgSTJMJAkGQaSJAwDSRKGgSQJw0DKlwVObsF6dXHdI4rajVQihoEOZ9cDD+TV1jRRu6IkHRXXQuDqtJvQ4cEw0OFsEfAxoCo+7w50APrm1U6Oy0rtlmGgw9lSwpt/n/j8POBh4Pm82gvAHxPr/RXhaGEXcBuQifX3AN8CXgS2AjOAY5v42ccCdwKbgU3ARA4EUL7+wDLgVWAL8KPEawOAx2IvzwBDYv27sfefAH+Kj1KLGQY6nL0JPAEMis8HAY8Ci/Nq+UcFnwD6AWcAlwMXxfrfx+l84ETgaJp+E54G7CMcdfQFLqTpIZ1b43QMcBIwO9Z7APMIQdIV+DowBzgOuCH+LuNjH+Ob2LZUEMNAh7tHOPDGfx7hDfTRvNojeetMIuyJ/x/hSKJPrH+GsNe+jrA3fj3hXEP+SeMaYDjwZeDPhKOIW2j6vMReQmhUx+0+HuufBebHaT/wIOEIYvhBf2OpBQwDHe4WAecS9qyPIwz/PEY4l9AV6M27jwxeSszvJux5A3yIMESU8yIhCGry1j+BMDy1mRAqu4B/Az7QRI9jgY8AqwlDW59IbOeyxDZ2xd+lexPbkVrMy+B0uPs9Yfz+GuB3sfYq4RzBNfFxfYHb+iPhDTrnw4ShoC1AbaK+EXiDsKe/r4DtrgFGEXbOPgXcA3SL2/mP2GdjvOWwisYjAx3uXicMrXyVMDyUszjWmnMV0d3AV4CehKOF7wGzePcb/mbgN8APCecB3kM4FzC4ie1+lnDUsp+w90+c/wXwN4RzFlVAR8IJ5FzwbCGcu5BazTBQe/AIYYhmcaL2aKw1JwymEvbUFxGOJvYAX2xi2auAI4FVwMuEvf2mhneGAisJ5wtuJZxbeJ1wZDAS+CawLT6fwIG/21uBS+P2Jzfj95DeJeOX20iSPDKQJBkGkiTDQJKEYSBJooI/Z1BdXZ2tq6tLuw1JqihPPvnk9mw2e1x+vWLDoK6ujmXLlqXdhiRVlEwm82JjdYeJJEmGgSTJMJAkUcHnDCSpOfbu3UtDQwN79uxJu5WS6NixI7W1tXTo0KGg5Q0DSe1CQ0MDnTp1oq6ujkwmc+gVKlg2m2XHjh00NDTQs2fPgtZxmEhSu7Bnzx66det22AcBQCaToVu3bs06CjIMJLUb7SEIcpr7uxoGkiTPGUhqn+rq5xV1exsmjTjo67t27WLmzJlce+21Ldr+8OHDmTlzJp07d27R+ofSbsKg2P/h8x3qfwRJ7duuXbu4/fbbWxwG8+fPL3JH7+QwkSSVQH19PS+88AJ9+vRhwoQJTJgwgd69e3P66acza9YsABYuXMigQYMYMWIEp5xyCl/4whfYv38/EG7Bs337dgBmzJjBGWecwZlnnsmVV15ZlP7azZGBJKVp0qRJrFixguXLlzNnzhx++tOf8swzz7B9+3b69evHoEGDAFiyZAmrVq3ihBNOYOjQodx7771ceumlb29n5cqVTJw4kccee4zq6mp27txZlP48MpCkElu8eDGjRo2iqqqKmpoaBg8ezNKlSwHo378/J554IlVVVYwaNYrFixe/Y92HHnqIyy67jOrqagC6du1alJ4MA0kqI/mXhJbqcljDQJJKoFOnTrz22msAnHfeecyaNYu33nqLbdu2sWjRIvr37w+EYaL169ezf/9+Zs2axbnnnvuO7VxwwQX86le/YseOHQBFGybynIGkdqnUVwB269aNgQMH0rt3b4YNG/b2CeBMJsPNN9/MBz/4QVavXk2/fv0YP348a9eu5fzzz+eSSy55x3ZOO+00brjhBgYPHkxVVRV9+/Zl2rRpre7PMJCkEpk5c+Y7nv/gBz941zLHHHMM999//7vqGzZseHt+9OjRjB49uqi9OUwkSfLIQJLKxZAhQxgyZEgqP9sjA0ntRjabTbuFkmnu72oYSGoXOnbsyI4dO9pFIOS+z6Bjx44Fr+MwkaR2oba2loaGBrZt25Z2KyWR+6azQhkGktqFDh06FPytX+1RIcNExwMPA6uAlcCXYv3bwCZgeZyGJ9a5HlgLPA9clKgPjbW1QH2i3hN4ItZnAUc255eQJLVOIWGwD/gacCowALguzgPcAvSJU+7+qqcCVwCnEd78bweq4nQbMCwuMyqxne/HbZ0MvAyMbfFvJElqtkLCYDPwVJx/DfgD0OMgy48Efgm8Aawn7O33j9NaYB3wZlxmJJABLgDuietPBy5uxu8gSWql5l5NVAf0JQzpAIwHngWmAl1irQewMbFOQ6w1Ve8G7CIcgSTrjRkHLIuTJKlImhMGRwNzgC8DrwJTgJMIQ0SbgR8WubfG3AGcHSdJUpEUejVRB0IQ3AXcG2tbEq//DMjdTGMT4aRzTm2s0UR9B9A59rIvb3lJUgkUcmSQAe4knCv4UaLePTF/CbAizs8lnEB+L+EqoV7AEmBpnO9JuFroirhslnC1Uu6rfEYD9zX/V5EktVQhRwYDgSuB5wiXkAJ8k3A1UB/Cm/kG4PPxtZXAbMKlqPsIVx+9FV8bDywgXFk0NS4L8A3CCeWJwNOE8JEklUghYbCYcHSQb34jtZzvxqmxdRpbbx3haiNJUgq8N5EkyTCQJBkGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkicLC4HjgYWAVsBL4Uqx3BR4E1sTHLrGeASYDa4FngbMS2xodl18T53M+CjwX15kctyFJKpFCwmAf8DXgVGAAcF2crwd+C/SKj/Vx+WGx1gsYB0yJ9a7AjcA5QP84nwuQKcA1ifWGtuJ3kiQ1UyFhsBl4Ks6/BvwB6AGMBKbH+nTg4jg/EpgBZIHHgc5Ad+AiwhHETuDlOD80vnZMXDYb181tS5JUAkc0c/k6oC/wBFBDCAqAl+JzCEGxMbFOQ6wdrN7QSL0x4+IkSSqi5oTB0cAc4MvAq3mvZePU1u6IU+5nSpKKoNCriToQguAu4N5Y20IY4iE+bo3zmwgnnXNqY+1g9dpG6pKkEikkDDLAnYRzBT9K1Ody4Iqg0cB9ifpVcb0BwCuE4aQFwIWEk8Zd4vyC+NqrcdlMXDe3LUlSCRQyTDQQuJJw6efyWPsmMAmYDYwFXgQuj6/NB4YTLhPdDYyJ9Z3ATcDS+Pw7sQZwLTANOAp4IE6SpBIpJAwW0/R1/x9vpJYlXH7amKlxyrcM6F1AL5KkNuAnkCVJhoEkyTCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJFBYGU4GtwIpE7dvAJmB5nIYnXrseWAs8D1yUqA+NtbVAfaLeE3gi1mcBRxbeviSpGAoJg2mEN/J8twB94jQ/1k4FrgBOi+vcDlTF6TZgWFxmVHwE+H7c1snAy8DY5v4SkqTWKSQMFgE7C9zeSOCXwBvAesLefv84rQXWAW/GZUYCGeAC4J64/nTg4gJ/liSpSFpzzmA88CxhGKlLrPUANiaWaYi1purdgF3Avrx6U8YBy+IkSSqSlobBFOAkwhDRZuCHxWroEO4Azo6TJKlIjmjhelsS8z8D7o/zm4DjE6/VxhpN1HcAnWMf+/KWlySVSEuPDLon5i/hwJVGcwknkN9LuEqoF7AEWBrnexKuFroiLpsFHgYujeuPBu5rYU+SpBYq5MjgbmAIUE0Y078xPu9DeDPfAHw+LrsSmA2sIuzpXwe8FV8bDywgXFk0NS4L8A3CCeWJwNPAnS39ZSRJLVNIGIxqpHawN+zvxinffA5cgpq0jnC1kSQpJX4CWZJkGEiSDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJJEYWEwFdgKrEjUugIPAmviY5dYzwCTgbXAs8BZiXVGx+XXxPmcjwLPxXUmx21IkkqokDCYBgzNq9UDvwV6xcf6WB8Wa72AccCUWO8K3AicA/SP87kAmQJck1gv/2dJktpYIWGwCNiZVxsJTI/z04GLE/UZQBZ4HOgMdAcuIhxB7ARejvND42vHxGWzcd3ctiRJJXJEC9erATbH+Zfic4AewMbEcg2xdrB6QyP1poyLkySpiFoaBknZOJXCHXHK/VxJUhG0NAy2EIZ4NsfHrbG+CTg+sVxtrG0ChuTVF8Z6bSPLK6Gufl6bbn/DpBFtun1J5a+ll5bO5cAVQaOB+xL1qwhXBA0AXiEExgLgQsJJ4y5xfkF87dW4bCaum9uWJKlECjkyuJuwV19NGNO/EZgEzAbGAi8Cl8dl5wPDCZeJ7gbGxPpO4CZgaXz+HQ6clL6WcMXSUcADcZIklVAhYTCqifrHG6llgeuaWH5qnPItA3oX0IckqY34CWRJkmEgSSrOpaXSQXk1lFT+PDKQJBkGkiTDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJPzQmXRIfmhO7YFHBpIkw0CSZBhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgSaL1YbABeA5YDiyLta7Ag8Ca+Ngl1jPAZGAt8CxwVmI7o+Pya+K8JKmEinFkcD7QBzg7Pq8Hfgv0io/1sT4s1noB44Apsd4VuBE4B+gf53MBIkkqgbYYJhoJTI/z04GLE/UZQBZ4HOgMdAcuIhxB7ARejvND26AvSVITWhsGWeA3wJOEvX2AGmBznH8pPgfoAWxMrNsQa03VGzOOMBy1rInXJUktcEQr1z8X2AR8gLBHvzrv9WyciuWOOOW2LUkqgtaGwab4uBX4T8KY/xbC8M/m+Lg1sezxiXVrY20TMCSvvrCVfUmK6urnten2N0wa0abbV2m0Zpjo/UCnxPyFwApgLgeuCBoN3Bfn5wJXEa4qGgC8QgiMBXHdLnG6MNYkSSXSmiODGsLRQG47M4FfA0uB2cBY4EXg8rjMfGA44dLS3cCYWN8J3BTXA/hOrEmSSqQ1YbAOOLOR+g7g443Us8B1TWxrapwkSSnwE8iSJMNAkmQYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJwBFpNyBJB1NXP69Nt79h0og23X6lKKcwGArcClQBPwcmpduOJLVepYRZuQwTVQG3AcOAU4FR8VGSVALlEgb9gbXAOuBN4JfAyFQ7kqR2JJPNZtPuAeBSwjDR1fH5lcA5wPi85cbFiaOOOuqUPXv2PN9WDdXU1FRv2bJle1ttvy1Vcu9g/2mz/3SVoP8TstnscfnFcjpnUIg74sTrr7/e1j9rGXB2W/+QNlLJvYP9p83+05VK/+UyTLQJOD7xvDbWJEklUC5hsBToBfQEjgSuAOam2pEktSPlMky0j3B+YAHhyqKpwMpUO4rDURWqknsH+0+b/acrlf7L5QSyJClF5TJMJElKkWEgSTIMJEmGgSQJw+Bwd3TaDbRQ17QbaKVPpt1AK1Xyv//JwKepjHubdU67gSTDAE4HHgc2Ei7p6pJ4bUkqHRXPqrQbKMC3EvOnAv8LPAlsINySpNx9Km/6NOH/o9zzcjcQ+APhUu5zgAcJn/vZCPxlin0V6mGgOs5fCcwn3PByFvDFtJoq0Hbgf4CxlEEweGkpLAYmEgLhamAMYc/uBeBpoG96rRXkq03UM8ANlP9e3lPAWXF+HvAT4AHCzQt/DHwsnbYKtpfw+ZithH9zCPfaugfIAp9Lqa9CLSG8GR0N/DdwMeFv4izgXwlhUc5WAL3j/FLCPc52AO8j/E2fkVJfhXgOuJ5wl+ahhH/3u4H7gDa/304+jwygE/BrYBfwL4QPv/0aGED4Yy533yMczXTKm46m8v77fogQBBDepI5KsZdCfYzQ51LCjsQYwh7fGMo/CAA6EN6Ufg9sI7whQQjpSvj33wv0iPN/Av4c598gfIC1nO0F7gc+Q7gFz13A5UADMLPUzZTLJ5DTdizwSpx/mHCoP4fy36uG8Ef7X4ShlXxXN1IrNycSbj2SIfxBvA/YHV/rkFZTzbAU+GvCkMTDwDeojJ2InOQOw/V5rx1ZykZa6CvAbwh/ryuBhwhHaucC/55iX4XIJOZfB2bH6VjCEVppm3GYiL8jfI/C43n1DwP/BFxT8o6a5xRgJ2GvLl8NsKW07TTb4LznTwGvEXq/lPClR5WiB3AL4Y6TJ6bcS6E+SRi33p1XP4mwU3RzyTtqvmMJf8cfIezgNhCGWlan2VQBvk4YjSgLhoEkqeLGlNvCsYTvW15N2MPeQbi6YhJlcIa/APafLvtPVyX3X1a9GwZhjO5lYAjhHEE34PxYm51eWwWz/3TZf7oquf+y6t1hInieMO7e3NfKhf2ny/7TVcn9l1XvHhnAi8A/Ek5Y5tQQrgrZmEpHzWP/6bL/dFVy/2XVu2EAf0s4PHuEcHi2E1hIOGy7PL22Cmb/6bL/dFVy/2XVu2EQLkf7HvAXhEsDf0L49DHAW2k11Qz2ny77T1cl919WvRsG4Ss2c59a/DHh07uTCNddl/uHVsD+02b/6ark/suqdz+BHAJxX5w/mwP3yVkMLE+joWay/3TZf7oquf+y6t0jg3CjqzFx/hnCfxQIh3B7U+moeew/Xfafrkruv6x699LS8MGPW4HzCDcYO4twJn8j8A+E/0jlzP7TZf/pquT+y6p3w+CAY4CeHLi3Sbnf0yef/afL/tNVyf2XRe+GgSTJcwaSJMNAkoRhIB3KY81cfgjh26ukimIYSAdX7t/BLBWFYSAd3J/i4xDCfWPuIdx//i4OfG3h0Fh7CvhUYt33Ez5lugR4GhgZ67cC/xznLwIW4d+iUuYnkKXC9QVOA/4I/A4YCCwDfgZcAKwFZiWWv4HwnbyfI3xZyRLCV0xeT/ju5EeBycBwYH8pfgGpKe6NSIVbQrgOfD/hdgF1hJuMrQfWAFngF4nlLwTq47ILgY6E79beTfhu7Qd5583JpNR4ZCAV7o3E/Fsc+u8nQ/hS+ecbee10wtccfqg4rUmt45GB1DqrCUcIJ8XnoxKvLQC+yIFzC33j4wnA1+LzYcA5bd6ldAiGgdQ6e4BxwDzCCeStidduAjoAzwIr4/MMcCfwdcK5h7HAzwlDSFJqvB2FJMkjA0mSYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRLw/8TYXbIYgTFrAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "dark"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "dark"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "dark"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "dark"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# (very) small EDA to check topics\n",
    "for df_tmp, title in zip([df, df_train, df_valid, df_test], [\"Whole set\", \"Train\", \"Valid\", \"Test\"]):\n",
    "    topic_counts = pd.DataFrame(df_tmp[\"topic\"].value_counts()).reset_index()\n",
    "    topic_counts[\"prop\"] = topic_counts[\"topic\"] / np.sum(topic_counts[\"topic\"])\n",
    "    display(topic_counts)\n",
    "    ax = topic_counts.plot.bar(x=\"index\", y=\"topic\")\n",
    "    ax.set_title(title)\n",
    "    ax.title.set_color(\"white\")\n",
    "    ax.xaxis.label.set_color(\"white\")\n",
    "    ax.tick_params(colors=\"white\", which=\"both\") \n",
    "\n",
    "# 606 and 607 probably be an issue\n",
    "# hopefully not the others"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As proposed by [Zahera et al. 2019](https://trec.nist.gov/pubs/trec28/papers/DICE_UPB.IS.pdf):\n",
    "- Stop-words, URLs, usernames and unicode-characters are removed.\n",
    "- Extra white-spaces, repeated full stops, question marks and exclamation marks are removed.\n",
    "- ~~Emojis were converted to text using the python library emoji~~\n",
    "- Lemmatization, restoring language vocabulary to general form (can express complete\n",
    "semantics) by WordNetLemmatizer 5 .\n",
    "- Finally all tweet tokens are converted to lower-case.\n",
    "  \n",
    "--- \n",
    "\n",
    "- add tweet type?\n",
    "- add authorusername?\n",
    "- not remove handles?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_stopwords = set(stopwords.words(\"english\"))\n",
    "tokenizer = TweetTokenizer(preserve_case=False, match_phone_numbers=False)\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess(txt):\n",
    "    tokens = tokenizer.tokenize(txt)\n",
    "\n",
    "    for i, token in enumerate(tokens):\n",
    "        if token in en_stopwords or token in (\",\", \"?\", \"!\", \":\", \".\"):\n",
    "            tokens[i] = \"[DEL]\"\n",
    "            continue\n",
    "        elif token.startswith(\"http\"):\n",
    "            tokens[i] = \"[URL]\"\n",
    "            continue\n",
    "        elif token.startswith(\"@\"):\n",
    "            tokens[i] = \"[HANDLE]\"\n",
    "            continue\n",
    "        else:\n",
    "            tokens[i] = lemmatizer.lemmatize(token)\n",
    "            \n",
    "    while True:\n",
    "        try:\n",
    "            tokens.remove(\"[DEL]\")\n",
    "        except ValueError:\n",
    "            break\n",
    "    return \" \".join(tokens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://t.co/HiFEZuBRRO\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[URL]'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tw = df[\"text\"].sample(1)\n",
    "print(tw.values[0])\n",
    "preprocess(tw.values[0])\n",
    "\n",
    "# tw = \"Our message to business is clear: @amor if you stand by your workers, we will stand by you. https://t.co/lWMKVlSFyz\"\n",
    "# preprocess(tw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, X_test = df_train[\"text\"], df_valid[\"text\"], df_test[\"text\"]\n",
    "y_train, y_valid, y_test = df_train[\"topic\"], df_valid[\"topic\"], df_test[\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Baseline (Multinomial naive bayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf',\n",
       "                 TfidfVectorizer(preprocessor=<function preprocess at 0x7f8e61e75b80>,\n",
       "                                 tokenizer=<bound method TweetTokenizer.tokenize of <nltk.tokenize.casual.TweetTokenizer object at 0x7f8e64fe3310>>)),\n",
       "                ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(preprocessor=preprocess, tokenizer=tokenizer.tokenize)),\n",
    "    (\"clf\", MultinomialNB())\n",
    "])\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       601.0       0.83      0.50      0.62      1750\n",
      "       602.0       0.56      0.97      0.71      4975\n",
      "       603.0       0.89      0.27      0.41       797\n",
      "       604.0       0.73      0.20      0.31      1417\n",
      "       605.0       0.73      0.17      0.28      1579\n",
      "       606.0       0.00      0.00      0.00        98\n",
      "       607.0       0.00      0.00      0.00        48\n",
      "\n",
      "    accuracy                           0.60     10664\n",
      "   macro avg       0.53      0.30      0.33     10664\n",
      "weighted avg       0.67      0.60      0.55     10664\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/olivier/.virtualenvs/covid-unige/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/olivier/.virtualenvs/covid-unige/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/olivier/.virtualenvs/covid-unige/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "y_pred = pipe.predict(X_valid)\n",
    "print(classification_report(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, classes 606 and 607 are not predicted at all. The multinomial model performs worse than the naive baseline of classifying all tweets as 602 (would get ~46% accuracy). \n",
    "\n",
    "Also note the huge difference between precision and recall:\n",
    "need to investigate why 602 tweets performs differently than the others, meaning that it has a big recall but low precision (like all the others)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bert\n",
    "Adapted from [here](https://towardsdatascience.com/multi-class-text-classification-with-deep-learning-using-bert-b59ca2f5c613)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{602: 0, 604: 1, 605: 2, 601: 3, 603: 4, 606: 5, 607: 6}\n"
     ]
    }
   ],
   "source": [
    "# Labels\n",
    "possible_labels = y_train.unique()\n",
    "\n",
    "label_dict = {\n",
    "    possible_label: index\n",
    "    for index, possible_label in enumerate(possible_labels)\n",
    "}\n",
    "\n",
    "print(label_dict)\n",
    "y_train, y_valid = y_train.replace(label_dict), y_valid.replace(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True)\n",
    "\n",
    "encoded_data_train = tokenizer.batch_encode_plus(\n",
    "    X_train.values,\n",
    "    add_special_tokens=True,\n",
    "    return_attention_mask=True,\n",
    "    padding=True,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "\n",
    "encoded_data_val = tokenizer.batch_encode_plus(\n",
    "    X_valid.values,\n",
    "    add_special_tokens=True,\n",
    "    return_attention_mask=True,\n",
    "    padding=True,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "\n",
    "input_ids_train = encoded_data_train[\"input_ids\"]\n",
    "attention_masks_train = encoded_data_train[\"attention_mask\"]\n",
    "labels_train = torch.tensor(y_train.values)\n",
    "\n",
    "input_ids_val = encoded_data_val[\"input_ids\"]\n",
    "attention_masks_val = encoded_data_val[\"attention_mask\"]\n",
    "labels_val = torch.tensor(y_valid.values)\n",
    "\n",
    "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)\n",
    "\n",
    "# To pickle\n",
    "pickle.dump(dataset_train, open(os.path.join(PKL_PATH, \"eng_train.pkl\"), \"wb\"))\n",
    "pickle.dump(dataset_val, open(os.path.join(PKL_PATH, \"eng_val.pkl\"), \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from pickle\n",
    "dataset_train = pickle.load(open(os.path.join(PKL_PATH, \"eng_train.pkl\"), \"rb\"))\n",
    "dataset_val = pickle.load(open(os.path.join(PKL_PATH, \"eng_val.pkl\"), \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\",\n",
    "    num_labels=len(y_train.unique()),\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False,\n",
    ")\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "dataloader_train = DataLoader(\n",
    "    dataset_train, sampler=RandomSampler(dataset_train), batch_size=batch_size\n",
    ")\n",
    "dataloader_validation = DataLoader(\n",
    "    dataset_val, sampler=SequentialSampler(dataset_val), batch_size=batch_size\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=1e-5, eps=1e-8)\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=0, num_training_steps=len(dataloader_train) * epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score_func(preds, labels):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return f1_score(labels_flat, preds_flat, average='weighted')\n",
    "\n",
    "def accuracy_per_class(preds, labels):\n",
    "    label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
    "    \n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "\n",
    "    for label in np.unique(labels_flat):\n",
    "        y_preds = preds_flat[labels_flat==label]\n",
    "        y_true = labels_flat[labels_flat==label]\n",
    "        acc_rate = len(y_preds[y_preds==label]) / len(y_true)\n",
    "        print(f'Class: {label_dict_inverse[label]}')\n",
    "        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)} ({np.round(acc_rate * 100, 2)}%)\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader_val):\n",
    "    model.eval()\n",
    "\n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [], []\n",
    "\n",
    "    for batch in dataloader_val:\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "\n",
    "        inputs = {\n",
    "            \"input_ids\": batch[0],\n",
    "            \"attention_mask\": batch[1],\n",
    "            \"labels\": batch[2],\n",
    "        }\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_val_total += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs[\"labels\"].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "\n",
    "    loss_val_avg = loss_val_total / len(dataloader_val)\n",
    "\n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "\n",
    "    return loss_val_avg, predictions, true_vals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "122024e073bb4b86a8de73970e46fba1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/1333 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1, took 246.03019760106665min\n",
      "Training loss: 0.8639154000248305\n",
      "Validation loss: 0.660720029455459\n",
      "Validation F1 Score (Weighted): 0.7522009696635154\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/1333 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2, took 244.31977857020004min\n",
      "Training loss: 0.5769600344281043\n",
      "Validation loss: 0.615461541774744\n",
      "Validation F1 Score (Weighted): 0.7759987082788163\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/1333 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3, took 245.01348518608333min\n",
      "Training loss: 0.46926281797376146\n",
      "Validation loss: 0.6157741198193527\n",
      "Validation F1 Score (Weighted): 0.778509385643326\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/1333 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4, took 244.9925754812666min\n",
      "Training loss: 0.3966452884365541\n",
      "Validation loss: 0.613605668199455\n",
      "Validation F1 Score (Weighted): 0.7855926672547904\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5:   0%|          | 0/1333 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5, took 244.3693329992333min\n",
      "Training loss: 0.3484602268486209\n",
      "Validation loss: 0.6266270353944002\n",
      "Validation F1 Score (Weighted): 0.7869417775033561\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "MODELS_PATH = os.path.join(app_run.root_dir, \"interactive\", \"data\", \"models\")\n",
    "\n",
    "for epoch in tqdm(range(1, epochs + 1)):\n",
    "    t1 = perf_counter()\n",
    "\n",
    "    model.train()\n",
    "    loss_train_total = 0\n",
    "\n",
    "    progress_bar = tqdm(\n",
    "        dataloader_train, desc=\"Epoch {:1d}\".format(epoch), leave=False, disable=False\n",
    "    )\n",
    "\n",
    "    for batch in progress_bar:\n",
    "        model.zero_grad()\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        inputs = {\n",
    "            \"input_ids\": batch[0],\n",
    "            \"attention_mask\": batch[1],\n",
    "            \"labels\": batch[2],\n",
    "        }\n",
    "        \n",
    "        outputs = model(**inputs)\n",
    "\n",
    "        loss = outputs[0]\n",
    "        loss_train_total += loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        progress_bar.set_postfix(\n",
    "            {\"training_loss\": \"{:.3f}\".format(loss.item() / len(batch))}\n",
    "        )\n",
    "\n",
    "    torch.save(model.state_dict(), os.path.join(MODELS_PATH, f\"finetuned_BERT_e_{epoch}.model\"))\n",
    "\n",
    "    tqdm.write(f\"\\nEpoch {epoch}, took {(perf_counter() - t1) / 60}min\")\n",
    "\n",
    "    loss_train_avg = loss_train_total / len(dataloader_train)\n",
    "    tqdm.write(f\"Training loss: {loss_train_avg}\")\n",
    "\n",
    "    val_loss, predictions, true_vals = evaluate(dataloader_validation)\n",
    "    val_f1 = f1_score_func(predictions, true_vals)\n",
    "    tqdm.write(f\"Validation loss: {val_loss}\")\n",
    "    tqdm.write(f\"Validation F1 Score (Weighted): {val_f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 602\n",
      "Accuracy: 4236/4975 (85.15%)\n",
      "\n",
      "Class: 604\n",
      "Accuracy: 928/1417 (65.49%)\n",
      "\n",
      "Class: 605\n",
      "Accuracy: 1088/1579 (68.9%)\n",
      "\n",
      "Class: 601\n",
      "Accuracy: 1484/1750 (84.8%)\n",
      "\n",
      "Class: 603\n",
      "Accuracy: 577/797 (72.4%)\n",
      "\n",
      "Class: 606\n",
      "Accuracy: 59/98 (60.2%)\n",
      "\n",
      "Class: 607\n",
      "Accuracy: 23/48 (47.92%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy_per_class(predictions, true_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CT-BERT\n",
    "[Mller et al. 2020](https://arxiv.org/abs/2005.07503)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERTweet \n",
    "[Nguyen et al 2020](https://www.aclweb.org/anthology/2020.emnlp-demos.2.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "607ef8f85d38ab7d98d9598c26f0a0f70958ff3fe818996b9742fe1433b73592"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
